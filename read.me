Projekt: Tolkning av handskriven text
Problemdefinition

Målet med detta projekt är att utveckla en maskininlärningsmodell som kan tolka handskriven text och konvertera den till digital text. Detta kan vara användbart inom flera områden, såsom:

    Automatisering av dokumenthantering
    Tillgänglighet för personer med funktionsnedsättningar
    Förbättrad igenkänning av text i äldre dokument

Verktyget ska kunna tolka bokstäver, siffror och symboler från bilder och översätta dessa till digitalt textformat.
Mål

Projektets huvudsakliga mål:

    Utveckla en modell som kan tolka en bred variation av handstilar
    Översätta handskriven text till ett digitalt format med hög precision
    Undvika vanliga felaktigheter i tolkning, t.ex. genom att skilja mellan liknande tecken (som 'O' och '0', eller '1' och 'I').

Dataset

För att träna och testa modellen använder vi ett dataset med bilder av handskrivna bokstäver och siffror, samt etiketter som anger vilket tecken varje bild representerar.

Exempel på dataset:

    MNIST - Innehåller handskrivna siffror (0–9) i 28x28 pixlar.
    EMNIST (Extended MNIST) - Innehåller en större variation, inklusive både bokstäver och siffror.

Val av dataset

Vi har valt EMNIST Letters-datasetet eftersom det innehåller både bokstäver och siffror, vilket matchar projektets mål. Datasetet har cirka 145 000 bilder och är lagrat som 28x28 pixlar i svartvitt.
Datakvalitet och format

    Kvalitet: Datasetet är beprövat och används ofta inom maskininlärning.
    Null-värden: Inga null-värden, då varje bild har en etikett.
    Datatyper: Varje bild representeras av en array av pixlar (värden mellan 0–255), och etiketten är ett heltal som representerar bokstaven eller siffran.

Typ av problem

Detta är ett klassificeringsproblem där vi vill klassificera varje bild till en specifik bokstav eller siffra.
Modell och träningsmetod

För att lösa detta problem använder vi Convolutional Neural Networks (CNNs), som är särskilt lämpade för att känna igen mönster i bilder och för att tolka handskriven text.

Vi kan börja med en enkel CNN-arkitektur och öka dess komplexitet baserat på resultatet. För att förfina modellen ytterligare överväger vi:

    Transfer Learning: Använda förtränade modeller för liknande data.
    Data Augmentation: Introducera små variationer i bilderna, som rotationer eller ljusförändringar, för att öka modellens robusthet.

Databearbetning och förberedelse

För att optimera datasetet för modellträning:

    Normalisering: Konvertera pixelvärden från 0-255 till 0-1.
    One-hot encoding: Konvertera etiketter till one-hot-format så att modellen kan förstå klasserna som distinkta utgångar.

Träningsplattform

Vi använder TensorFlow som träningsplattform, då det ger kompatibilitet och tillgång till bibliotek för CNN-modeller.
Utvärdering av modellens prestanda

För att mäta modellens prestanda använder vi:

    Accuracy: För att mäta antalet korrekta klassificeringar.
    Confusion Matrix: För att analysera vilka tecken som eventuellt förväxlas